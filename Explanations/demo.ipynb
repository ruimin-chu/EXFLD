{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer, EncoderNormalizer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ],
   "id": "4fc24732576ef9be"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af185fa9a9216be0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(df):\n",
    "    dl = TimeSeriesDataSet(\n",
    "        df,\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"Var_tc_readjusted\",\n",
    "        group_ids=[\"group_id\"],\n",
    "        min_encoder_length=max_encoder_length,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=max_prediction_length,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"group_id\", \"Site_No\"],\n",
    "        static_reals=[\"tank_max_height\", \"tank_max_volume\"],\n",
    "        time_varying_known_categoricals=[\"Time_of_day\"],\n",
    "        time_varying_known_reals=[\"time_idx\", \"ClosingHeight_tc_readjusted\" ,\"ClosingStock_tc_readjusted\", \"TankTemp\"],\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[\n",
    "            \"Var_tc_readjusted\"\n",
    "        ],\n",
    "        target_normalizer=EncoderNormalizer(\n",
    "            method='robust',\n",
    "            max_length=None,\n",
    "            center=True,\n",
    "            transformation=None,\n",
    "            method_kwargs={}\n",
    "        ),\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "        allow_missing_timesteps=True\n",
    "    )\n",
    "    return dl"
   ],
   "id": "5dc8789eb7e97a82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = pd.read_csv('../test_tl_AN.csv')\n",
    "path = os.getcwd() + '/15day_norm/trial_2/epoch=38.ckpt' \n",
    "batch_size = 128\n",
    "max_prediction_length = 72\n",
    "max_encoder_length = 240\n",
    "\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(path)\n",
    "tlgrouths = pd.read_csv('tankleakage_info.csv', index_col=0).reset_index(drop=True)\n",
    "tank_sample_id = 'D143_5'\n",
    "\n",
    "test_seq = test_sequence[(test_sequence['group_id'] == tank_sample_id)]\n",
    "test_seq = test_seq[abs(test_seq['Var_tc_readjusted']) < 1]\n",
    "test_seq = test_seq.reset_index(drop=True)\n",
    "test_seq['time_idx'] = test_seq.index\n",
    "\n",
    "site_id = tank_sample_id[:4]\n",
    "tank_id = tank_sample_id[-1]\n",
    "tank_info = tlgrouths[(tlgrouths['Site'] == site_id) & (tlgrouths['Tank'] == int(tank_id))]\n",
    "startdate = tank_info.iloc[0]['StartDate']\n",
    "stopdate = tank_info.iloc[0]['StopDate']\n",
    "temp_df = test_seq[test_seq['Time_DN'] > startdate]\n",
    "startindex = temp_df.iloc[0]['time_idx']\n",
    "op = startindex - max_encoder_length - 500\n",
    "ed = startindex + max_prediction_length + 500"
   ],
   "id": "5ff5347ee3c34c11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_dataloader(test_seq)\n",
    "test_data = TimeSeriesDataSet.from_dataset(test,  test_seq[lambda x: (x.time_idx < ed) & (x.time_idx >= op)], stop_randomization=True)\n",
    "xs = test_seq[lambda x: (x.time_idx < ed) & (x.time_idx >= op)]['Time'].array\n",
    "actual = test_seq[lambda x: (x.time_idx < ed) & (x.time_idx >= op)]['Var_tc_readjusted'].array\n",
    "predictions = best_tft.predict(test_data, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "y_hat = []\n",
    "for i in range(predictions.output[\"prediction\"].data.shape[0]):\n",
    "    y_hat.append(predictions.output[\"prediction\"].data[i, 0, 3].numpy().min())\n",
    "y_hat = y_hat + predictions.output[\"prediction\"].data[-1, :, 3].numpy().tolist()[1:]\n",
    "y_quantile = np.empty((len(xs[max_encoder_length:]), predictions.output[\"prediction\"].data.shape[-1]))\n",
    "for i in range(predictions.output[\"prediction\"].data.shape[0]):\n",
    "    y_quantile[i, :] = predictions.output[\"prediction\"].data[i, 0, :].numpy()\n",
    "y_quantile[-max_prediction_length+1:, :] = predictions.output[\"prediction\"].data[-1, 1:, :].numpy()\n",
    "\n",
    "xs_plt = mdates.date2num(xs[max_encoder_length:])\n",
    "fig, ax = plt.subplots(figsize=(18,9))\n",
    "ax.plot(xs_plt, actual[max_encoder_length:], label=\"actual\")\n",
    "ax.plot(xs_plt, y_hat, label=\"prediction\", alpha=0.75, color='C1')\n",
    "ax.plot(xs_plt[500:500+max_prediction_length], y_hat[500:500+max_prediction_length], alpha=0.75, color='red')\n",
    "for i in range(y_quantile.shape[1] // 2):\n",
    "    ax.fill_between(xs_plt, y_quantile[:, i], y_quantile[:, -i - 1], alpha=0.25+i*0.1, fc='C1')\n",
    "    ax.fill_between(xs_plt[500:500+max_prediction_length], y_quantile[500:500+max_prediction_length, i], y_quantile[500:500+max_prediction_length, -i - 1], color='red', alpha=0.25+i*0.1)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "ax.legend(fontsize=16)\n",
    "ax.set_xlabel(\"Time\", fontsize=16)\n",
    "ax.set_ylabel(\"Fuel Variance\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "88b6b0b7385b76db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(predictions.output, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ],
   "id": "29c4d80b0c6a7c5b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textual Explanation "
   ],
   "id": "b24daff06b9596e5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T05:15:26.106169700Z",
     "start_time": "2024-11-14T05:15:20.443142400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.pardir))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ANFIS.load_weights as load_weights\n",
    "import torch\n",
    "import re\n",
    "from IPython.display import Markdown, display"
   ],
   "id": "a571687f9e7f5306"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T05:15:32.161484900Z",
     "start_time": "2024-11-14T05:15:32.140210900Z"
    }
   },
   "outputs": [],
   "source": [
    "def daily_format(df):\n",
    "    df = df[df['period'] == 0]\n",
    "    daily = pd.DataFrame(columns=['Day', 'TankTemp', 'ClosingStock_tc_readjusted', 'ClosingHeight_tc_readjusted', 'Var_tc_readjusted'])\n",
    "    for day, day_group in df.groupby(df['Time'].dt.date):\n",
    "        last_status = day_group.iloc[-1]\n",
    "        daily.loc[-1] = [day, last_status['TankTemp'], last_status['ClosingStock_tc_readjusted'],\n",
    "                         last_status['ClosingHeight_tc_readjusted'], day_group['Var_tc_readjusted'].sum()]\n",
    "        daily.index = daily.index + 1\n",
    "        daily = daily.sort_index()\n",
    "    return daily\n",
    "\n",
    "def gaussian(x, mean, sigma):\n",
    "    return np.exp(-((x - mean) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "def membership_recent(x):\n",
    "    if x < 1 or x > 7:\n",
    "        return 0\n",
    "    elif 1 <= x <= 3:\n",
    "        return 1\n",
    "    elif 3 < x <= 7:\n",
    "        return (7 - x) / (7 - 3)\n",
    "    \n",
    "def membership_medium(x):\n",
    "    if x <= 3 or x > 19:\n",
    "        return 0\n",
    "    elif 3 < x < 10:\n",
    "        return (x - 3) / (10 - 3)\n",
    "    elif 10 <= x <= 15:\n",
    "        return 1\n",
    "    elif 15 < x <= 19:\n",
    "        return (19 - x) / (19 - 15)\n",
    "    \n",
    "def membership_long(x):\n",
    "    if x <= 15 or x > 30:\n",
    "        return 0\n",
    "    elif 15 < x < 25:\n",
    "        return (x - 15) / (25 - 15)\n",
    "    elif 25 <= x <= 30:\n",
    "        return 1\n",
    "    \n",
    "def create_data(sample):\n",
    "    sample = sample.sort_values(by='Day', ascending=True)\n",
    "    sample['Day_Order'] = sample['Day'].rank(ascending=False)\n",
    "    sample['Membership_Recent'] = sample['Day_Order'].apply(membership_recent)\n",
    "    sample['Membership_Medium'] = sample['Day_Order'].apply(membership_medium)\n",
    "    sample['Membership_Long'] = sample['Day_Order'].apply(membership_long)\n",
    "    sample['Membership_Recent'] = sample['Membership_Recent'] / sample['Membership_Recent'].sum()\n",
    "    sample['Membership_Medium'] = sample['Membership_Medium'] / sample['Membership_Medium'].sum()\n",
    "    sample['Membership_Long'] = sample['Membership_Long'] / sample['Membership_Long'].sum()\n",
    "\n",
    "    Vartc_Recent = (sample['Var_tc_readjusted'] * sample['Membership_Recent']).sum()\n",
    "    Vartc_Medium = (sample['Var_tc_readjusted'] * sample['Membership_Medium']).sum()\n",
    "    Vartc_Long = (sample['Var_tc_readjusted'] * sample['Membership_Long']).sum()\n",
    "    ClosingHeight_tc_Recent = (sample['ClosingHeight_tc_readjusted'] * sample['Membership_Recent']).sum()\n",
    "    ClosingStock_tc_Recent = (sample['ClosingStock_tc_readjusted'] * sample['Membership_Recent']).sum()\n",
    "    Temp_Recent = (sample['TankTemp'] * sample['Membership_Recent']).sum()\n",
    "\n",
    "    var_rec_med = Vartc_Recent - Vartc_Medium\n",
    "    var_rec_long = Vartc_Recent - Vartc_Long\n",
    "    features = [var_rec_med, var_rec_long, ClosingStock_tc_Recent, ClosingHeight_tc_Recent, Temp_Recent]\n",
    "    return features"
   ],
   "id": "5ebce95680fc8539"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leakage example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41c6446f3fb1bfbb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\"Define the setup\"\"\"\n",
    "diff = {0: 'very negative', 1: 'moderately negative', 2: 'near zero', 3: 'positive'}\n",
    "pos = {0: 'very low', 1: 'low', 2: 'middle', 3: 'high', 4: 'very high'}\n",
    "window_size = pd.Timedelta(days=30)\n",
    "columns_sel = ['(Fuel Variance of recent period - Fuel Variance of medium period)', '(Fuel Variance of recent period - Fuel Variance of long period)', 'Inventory height of recent period', 'Likelihood']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T05:15:37.126508200Z",
     "start_time": "2024-11-14T05:15:37.110676600Z"
    }
   },
   "id": "1ad33e46fa52e23b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"Load the leakage example\"\"\"\n",
    "df_test = pd.read_csv('../test_tl_AN.csv', header=0, sep=',')\n",
    "tlgrouths = pd.read_csv('../tankleakage_info_AN.csv',index_col=0).reset_index(drop=True)\n",
    "df_test['Time'] = pd.to_datetime(df_test['Time'])\n",
    "site, tank_id = 'D143', '1'\n",
    "tank_sample_id = site + '_' + tank_id\n",
    "tank_df = df_test[df_test['group_id'] == tank_sample_id]\n",
    "tank_info = tlgrouths[(tlgrouths['Site'] == site) & (tlgrouths['Tank'] == int(tank_id))]\n",
    "startdate = tank_info.iloc[0]['StartDate']\n",
    "temp_df = tank_df[tank_df['Time_DN'] > startdate]\n",
    "end_date = temp_df.iloc[0]['Time'] + pd.Timedelta(days=3)\n",
    "start_date = end_date - window_size\n",
    "sub_df = tank_df[(tank_df['Time'] >= start_date) & (tank_df['Time'] <= end_date)]\n",
    "daily = daily_format(sub_df)\n",
    "feature = create_data(daily)\n",
    "list_val = np.array(feature[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T05:15:42.830831400Z",
     "start_time": "2024-11-14T05:15:37.980783900Z"
    }
   },
   "id": "304c806bcaa4792f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load model for the tank\"\"\"\n",
    "model = torch.load('models/model_' + site + '.h5')\n",
    "pred = model(torch.Tensor([list_val]))\n",
    "pred2 = torch.argmax(pred, 1)\n",
    "pred2 = pred2.detach().numpy()\n",
    "\n",
    "if pred2 == 0:\n",
    "    res = 'non-leakage'\n",
    "else:\n",
    "    res = 'leakage'\n",
    "\n",
    "rule, firerule, index_rule = load_weights.get_fire_strength(model, pred2)\n",
    "numeric_pattern = r'\\d+\\.\\d+'\n",
    "numeric_values = [float(match) for match in re.findall(numeric_pattern, rule)]\n",
    "conf_score = max(numeric_values)\n",
    "\n",
    "cons, rstr = load_weights.read_rule(model)\n",
    "exp = index_rule[0]\n",
    "list_exp = []\n",
    "for l in range(len(columns_sel) - 1):\n",
    "    deg = model.layer['rules'].mf_indices[exp, l].item()\n",
    "    if l == 0 or l == 1:\n",
    "        descrp = diff.get(deg)\n",
    "    else:\n",
    "        descrp = pos.get(deg)\n",
    "    ant = columns_sel[l] + \" is \" + descrp\n",
    "    list_exp.append(ant)"
   ],
   "id": "6c7c72d646f3a04a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The top firing rule is RULE 21 with a firing strength of 0.52:  \n",
       " IF *(Fuel Variance of recent period - Fuel Variance of medium period)* is **moderately negative**  \n",
       " AND *(Fuel Variance of recent period - Fuel Variance of long period)* is **moderately negative**  \n",
       " AND *Inventory height of recent period* is **low**  \n",
       " THEN the case is **leakage**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Feature Descriptions are:  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*(Fuel Variance of recent period - Fuel Variance of medium period)* is **moderately negative** with a membership of 98.09%, and **very negative** with a membership of 9.87%."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*(Fuel Variance of recent period - Fuel Variance of long period)* is **moderately negative** with a membership of 77.44%, and **very negative** with a membership of 26.42%."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Inventory height of recent period* is **low** with a membership of 68.16%, and **middle** with a membership of 26.99%."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Generate the explanation to observe the degree of the difference for change point\"\"\"\n",
    "reasons = []\n",
    "for j in index_rule[0:1]:  \n",
    "    # First display the top firing rule    \n",
    "    rr = 'The top firing rule is RULE ' + str(j) + ' with a firing strength of ' + str(round(firerule.get(j), 2)) + ':  \\n IF '\n",
    "    for l in range(len(columns_sel) - 1):\n",
    "        deg = model.layer['rules'].mf_indices[j, l].item()\n",
    "        if l == 0 or l == 1:\n",
    "            descrp = diff.get(deg)\n",
    "        else:\n",
    "            descrp = pos.get(deg)\n",
    "        if l == len(columns_sel) - 2:\n",
    "            rr += f\"*{columns_sel[l]}* is **{descrp}**\"\n",
    "        else:\n",
    "            rr += f\"*{columns_sel[l]}* is **{descrp}**  \\n AND \"\n",
    "\n",
    "    temp = rstr[j]\n",
    "    numeric_pattern = r'\\d+\\.\\d+'\n",
    "    numeric_values = [float(match) for match in re.findall(numeric_pattern, temp)]\n",
    "    max_value = max(numeric_values)\n",
    "    preds = numeric_values.index(max_value)\n",
    "    if preds == 0:\n",
    "        res = 'non-leakage'\n",
    "    else:\n",
    "        res = 'leakage'\n",
    "    \n",
    "    rr += f\"  \\n THEN the case is **{res}**\"\n",
    "    display(Markdown(rr)) \n",
    "\n",
    "    display(Markdown(\"\"))\n",
    "\n",
    "    # Feature description with linguistic terms are displayed \n",
    "    memberships = model.fuzzified[0, :, :]\n",
    "    top_values, top_indices = torch.topk(memberships.data, k=2, dim=-1)\n",
    "    text = '### Feature Descriptions are:  \\n'\n",
    "    display(Markdown(text))\n",
    "    \n",
    "    for i in range(memberships.size(0)):\n",
    "        var = columns_sel[i]\n",
    "        if i != 2:\n",
    "            top1 = diff.get(top_indices[i][0].item())\n",
    "            top2 = diff.get(top_indices[i][1].item())\n",
    "        else:\n",
    "            top1 = pos.get(top_indices[i][0].item())\n",
    "            top2 = pos.get(top_indices[i][1].item())\n",
    "        \n",
    "        text = (\n",
    "            f\"*{var}* is \"\n",
    "            + f'**{top1}** with a membership of {str(round(top_values[i][0].item() * 100, 2))}%, and '\n",
    "            + f'**{top2}** with a membership of {str(round(top_values[i][1].item() * 100, 2))}%.'\n",
    "        )\n",
    "        display(Markdown(text))"
   ],
   "id": "f65cd28b6e5c4646"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
